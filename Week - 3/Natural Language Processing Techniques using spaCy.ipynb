{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5188de248cf334b502219f51021fcd69acb394b"
   },
   "source": [
    "## Natural Language Processing Techniques using spaCy \n",
    "\n",
    "This notebook explains NLP techniques using python's library - spaCy\n",
    "\n",
    "### Contents \n",
    "\n",
    "1. About spaCy  \n",
    "2. Installation  \n",
    "3. Dataset Preparation for spaCy  \n",
    "4. Tokenization - Word and Sentences  \n",
    "5. Text Cleaning - Stopwords, Punctuations, Lemmatization  \n",
    "6. Part of Speech Tagging  \n",
    "7. Entity Extraction  \n",
    "8. Noun Phrase Chunking  \n",
    "9. Dependency Parsing  \n",
    "10. Word Vector Notations  \n",
    "\n",
    "### 1. About spaCy \n",
    "\n",
    "spaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python. It's designed specifically for production use and helps you build applications that process and \"understand\" large volumes of text. It can be used to build information extraction or natural language understanding systems, or to pre-process text for deep learning. Following are the key features of spaCy : \n",
    "\n",
    "- Non-destructive tokenization\n",
    "- Named entity recognition\n",
    "- Support for 34+ languages\n",
    "- 13 statistical models for 8 languages\n",
    "- Pre-trained word vectors\n",
    "- Easy deep learning integration\n",
    "- Part-of-speech tagging\n",
    "- Labelled dependency parsing\n",
    "- Syntax-driven sentence segmentation\n",
    "- Built in visualizers for syntax and NER\n",
    "- Convenient string-to-hash mapping\n",
    "- Export to numpy data arrays\n",
    "- Efficient binary serialization\n",
    "- Easy model packaging and deployment\n",
    "- State-of-the-art speed\n",
    "- Robust, rigorously evaluated accuracy  \n",
    "\n",
    "With so many features inbuilt, spaCy is considered as one of the powerful NLP library. \n",
    "\n",
    "### 2. Installation \n",
    "\n",
    "To install spaCy, two steps are required, \n",
    "\n",
    "2.1 Install the spaCy source using pip command\n",
    "\n",
    "    pip install spacy\n",
    "\n",
    "2.2 Download the spacy pre-trained and annotated models  \n",
    "\n",
    "    python -m spacy download en_core_web_sm  \n",
    "    \n",
    "### 3. Dataset Preparation  \n",
    "\n",
    "We first load the required libraries and prepare the data for spaCy usage.  We will load the spacy models (which were downloaded duing the installation step) and create an object \"nlp\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in d:\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff5ed9e9b8ff194c3234c2c7c15d8827108f41bd"
   },
   "source": [
    "Consider that we have a text document obtained the movie plot obtained from wikipedia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "19293f77a8fc545bde5281c2cbdccc08c3d42efa"
   },
   "outputs": [],
   "source": [
    "doc = \"\"\"Alice follows a large white rabbit down a \"Rabbit-hole\". She finds a tiny door. When she finds a bottle labeled \"Drink me\", she does, and shrinks, but not enough to pass through the door. She then eats something labeled \"Eat me\" and grows larger. She finds a fan when enables her to shrink enough to get into the \"Garden\" and try to get a \"Dog\" to play with her. She enters the \"White Rabbit's tiny House,\" but suddenly resumes her normal size. In order to get out, she has to use the \"magic fan.\"\n",
    "She enters a kitchen, in which there is a cook and a woman holding a baby. She persuades the woman to give her the child and takes the infant outside after the cook starts throwing things around. The baby then turns into a pig and squirms out of her grip. \"The Duchess's Cheshire Cat\" appears and disappears a couple of times to Alice and directs her to the Mad Hatter's \"Mad Tea-Party.\" After a while, she leaves.\n",
    "The Queen invites Alice to join the \"ROYAL PROCESSION\": a parade of marching playing cards and others headed by the White Rabbit. When Alice \"unintentionally offends the Queen\", the latter summons the \"Executioner\". Alice \"boxes the ears\", then flees when all the playing cards come for her. Then she wakes up and realizes it was all a dream.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff89553ea717c5b78afdcb5b67431803a560d801"
   },
   "source": [
    "Before using the features of spacy,  we need to convert the text document into spacy document using the \"nlp\" object created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "f5f4a400882611bccdf41156274559356431a391"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice follows a large white rabbit down a \"Rabbit-hole\". She finds a tiny door. When she finds a bottle labeled \"Drink me\", she does, and shrinks, but not enough to pass through the door. She then eats something labeled \"Eat me\" and grows larger. She finds a fan when enables her to shrink enough to get into the \"Garden\" and try to get a \"Dog\" to play with her. She enters the \"White Rabbit's tiny House,\" but suddenly resumes her normal size. In order to get out, she has to use the \"magic fan.\"\n",
       "She enters a kitchen, in which there is a cook and a woman holding a baby. She persuades the woman to give her the child and takes the infant outside after the cook starts throwing things around. The baby then turns into a pig and squirms out of her grip. \"The Duchess's Cheshire Cat\" appears and disappears a couple of times to Alice and directs her to the Mad Hatter's \"Mad Tea-Party.\" After a while, she leaves.\n",
       "The Queen invites Alice to join the \"ROYAL PROCESSION\": a parade of marching playing cards and others headed by the White Rabbit. When Alice \"unintentionally offends the Queen\", the latter summons the \"Executioner\". Alice \"boxes the ears\", then flees when all the playing cards come for her. Then she wakes up and realizes it was all a dream."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_doc = nlp(doc)\n",
    "spacy_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef17605014a2108c7923b0147520c51c2856a5cf"
   },
   "source": [
    "### 4. Tokenization \n",
    "\n",
    "First, we will see how can we perform tokenization at word level and sentence level using spacy. \n",
    "\n",
    "**Word Level Tokenization** : To obtain word tokens, we just need to access the spacy document as list, all the tokens will be obtained. This is because when we converted the document into spacy document, this step was already performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "22c035d9c6f731f6ec0976d4a1e81852d2ae8fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice, follows, a, large, white, rabbit, down, a, \", Rabbit, -, hole, \", ., She, finds, a, tiny, door, ., When, she, finds, a, bottle, labeled, \", Drink, me, \", ,, she, does, ,, and, shrinks, ,, but, not, enough, to, pass, through, the, door, ., She, then, eats, something, labeled, \", Eat, me, \", and, grows, larger, ., She, finds, a, fan, when, enables, her, to, shrink, enough, to, get, into, the, \", Garden, \", and, try, to, get, a, \", Dog, \", to, play, with, her, ., She, enters, the, \", White, Rabbit, 's, tiny, House, ,, \", but, suddenly, resumes, her, normal, size, ., In, order, to, get, out, ,, she, has, to, use, the, \", magic, fan, ., \", \n",
      ", She, enters, a, kitchen, ,, in, which, there, is, a, cook, and, a, woman, holding, a, baby, ., She, persuades, the, woman, to, give, her, the, child, and, takes, the, infant, outside, after, the, cook, starts, throwing, things, around, ., The, baby, then, turns, into, a, pig, and, squirms, out, of, her, grip, ., \", The, Duchess, 's, Cheshire, Cat, \", appears, and, disappears, a, couple, of, times, to, Alice, and, directs, her, to, the, Mad, Hatter, 's, \", Mad, Tea, -, Party, ., \", After, a, while, ,, she, leaves, ., \n",
      ", The, Queen, invites, Alice, to, join, the, \", ROYAL, PROCESSION, \", :, a, parade, of, marching, playing, cards, and, others, headed, by, the, White, Rabbit, ., When, Alice, \", unintentionally, offends, the, Queen, \", ,, the, latter, summons, the, \", Executioner, \", ., Alice, \", boxes, the, ears, \", ,, then, flees, when, all, the, playing, cards, come, for, her, ., Then, she, wakes, up, and, realizes, it, was, all, a, dream, .]\n"
     ]
    }
   ],
   "source": [
    "tokens = list(spacy_doc)\n",
    "print (tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1424a33c7c1c1a18a57d7b5f9ad787ca753b620d"
   },
   "source": [
    "Similarly, for **sentence level tokenization**, we can acess the sentences using following syntax. It will give a generator object. \n",
    "\n",
    "    spacy_doc.sents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "2d7d35801f121650c52605acce1872698760c0e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Alice follows a large white rabbit down a \"Rabbit-hole\".\n",
      "1 She finds a tiny door.\n",
      "2 When she finds a bottle labeled \"Drink me\", she does, and shrinks, but not enough to pass through the door.\n",
      "3 She then eats something labeled \"Eat me\" and grows larger.\n",
      "4 She finds a fan when enables her to shrink enough to get into the \"Garden\" and try to get a \"Dog\" to play with her.\n",
      "5 She enters the \"White Rabbit's tiny House,\" but suddenly resumes her normal size.\n",
      "6 In order to get out, she has to use the \"magic fan.\"\n",
      "7 \n",
      "\n",
      "8 She enters a kitchen, in which there is a cook and a woman holding a baby.\n",
      "9 She persuades the woman to give her the child and takes the infant outside after the cook starts throwing things around.\n",
      "10 The baby then turns into a pig and squirms out of her grip. \"\n",
      "11 The Duchess's Cheshire Cat\" appears and disappears a couple of times to Alice and directs her to the Mad Hatter's \"Mad Tea-Party.\n",
      "12 \" After a while, she leaves.\n",
      "13 \n",
      "\n",
      "14 The Queen invites Alice to join the \"ROYAL PROCESSION\": a parade of marching playing cards and others headed by the White Rabbit.\n",
      "15 When Alice \"unintentionally offends the Queen\", the latter summons the \"Executioner\".\n",
      "16 Alice \"boxes the ears\", then flees when all the playing cards come for her.\n",
      "17 Then she wakes up and realizes it was all a dream.\n"
     ]
    }
   ],
   "source": [
    "for index, sentence in enumerate(spacy_doc.sents):\n",
    "    print (index, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "02a87ebb83ab84caf5e09602e0e29a7c05c58070"
   },
   "source": [
    "### 5. Text Cleaning \n",
    "\n",
    "In this section, we will see how can we access different properties of tokens produced in spacy object that can be used to remove noise in the text. Different properties of spacy tokens can be viewed using following syntax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "cc70b06a5a5a4d073620628e65a9112e9a0f171c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', 'ancestors', 'check_flag', 'children', 'cluster', 'conjuncts', 'dep', 'dep_', 'doc', 'ent_id', 'ent_id_', 'ent_iob', 'ent_iob_', 'ent_kb_id', 'ent_kb_id_', 'ent_type', 'ent_type_', 'get_extension', 'has_dep', 'has_extension', 'has_head', 'has_morph', 'has_vector', 'head', 'i', 'idx', 'iob_strings', 'is_alpha', 'is_ancestor', 'is_ascii', 'is_bracket', 'is_currency', 'is_digit', 'is_left_punct', 'is_lower', 'is_oov', 'is_punct', 'is_quote', 'is_right_punct', 'is_sent_end', 'is_sent_start', 'is_space', 'is_stop', 'is_title', 'is_upper', 'lang', 'lang_', 'left_edge', 'lefts', 'lemma', 'lemma_', 'lex', 'lex_id', 'like_email', 'like_num', 'like_url', 'lower', 'lower_', 'morph', 'n_lefts', 'n_rights', 'nbor', 'norm', 'norm_', 'orth', 'orth_', 'pos', 'pos_', 'prefix', 'prefix_', 'prob', 'rank', 'remove_extension', 'right_edge', 'rights', 'sent', 'sent_start', 'sentiment', 'set_extension', 'set_morph', 'shape', 'shape_', 'similarity', 'subtree', 'suffix', 'suffix_', 'tag', 'tag_', 'tensor', 'text', 'text_with_ws', 'vector', 'vector_norm', 'vocab', 'whitespace_']\n"
     ]
    }
   ],
   "source": [
    "first_word = tokens[0]   # 'Alice'\n",
    "print(dir(first_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f24e005b6541dee7fd43b3727c5068ec5347d344"
   },
   "source": [
    "We can see that there are many properties of every token. Let's view some of these properties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "5fd15d589c534599763615dd4208c15efc4f9360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_bracket:  False\n",
      "like_num:  False\n",
      "right_edge:  Alice\n",
      "sentiment:  0.0\n",
      "dep_:  nsubj\n",
      "is_sent_start: True\n"
     ]
    }
   ],
   "source": [
    "print (\"is_bracket: \", first_word.is_bracket)\n",
    "print (\"like_num: \", first_word.like_num)\n",
    "print (\"right_edge: \", first_word.right_edge)\n",
    "print (\"sentiment: \", first_word.sentiment)\n",
    "print (\"dep_: \", first_word.dep_)\n",
    "print ('is_sent_start:', first_word.is_sent_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c28c85d904580c205f00022f83e48e520fb4c06b"
   },
   "source": [
    "Using these properties, we can infact clean the text data. For example, following code cell shows how to remove the tokens which are punctuations and stopwords, and lemmatize the remaining ones. \n",
    "\n",
    "#### Removal of Punctionation \n",
    "\n",
    "property : is_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "7545e863080f3dac4d617869d7144faac89aacbb"
   },
   "outputs": [],
   "source": [
    "tokens = [t for t in tokens if (t.is_punct == False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bdb6f81eb56374bf3e19b49ad1fa1c00efd14646"
   },
   "source": [
    "#### Removal of Stopwords \n",
    "\n",
    "property : is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "d1534ad9d037f87e93e8b14792d029658b3b60b8"
   },
   "outputs": [],
   "source": [
    "tokens = [t for t in tokens if (t.is_stop == False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b049b6af808a51265e6572be13f0f9cd596dce1"
   },
   "source": [
    "#### Token lemmatization\n",
    "\n",
    "property : lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "15879607c719a9d64937e982b6f7990d7d4fa858"
   },
   "outputs": [],
   "source": [
    "lemmatized_words = [token.lemma_ for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "33171ba64381dff231882d20a1107c27bdd63497"
   },
   "source": [
    "Finally, we join these lemmatized words to produce a cleaned document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "3995204a51a06a3c4239179cd76787c8c648f849"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice follow large white rabbit rabbit hole find tiny door find bottle label drink shrink pass door eat label eat grow large find fan enable shrink Garden try Dog play enter White Rabbit tiny House suddenly resume normal size order use magic fan \\n enter kitchen cook woman hold baby persuade woman child take infant outside cook start throw thing baby turn pig squirm grip Duchess Cheshire Cat appear disappear couple time Alice direct mad Hatter mad Tea Party leave \\n Queen invite Alice join ROYAL PROCESSION parade marching playing card head White Rabbit Alice unintentionally offend queen summon Executioner alice box ear flee playing card come wake realize dream'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_doc = \" \".join(lemmatized_words)\n",
    "cleaned_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f615632a0b13c95d47f84121d23c0d34de1e6b71"
   },
   "source": [
    "### 6. Part of Speech Tagging \n",
    "\n",
    "Next, we look at how can we obtain part of speech tag associated with every token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "2b7d5c2605cf5109eae6320ac65554d2b16b1644"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:  Alice POS Tag:  PROPN\n",
      "Token:  follows POS Tag:  VERB\n",
      "Token:  a POS Tag:  DET\n",
      "Token:  large POS Tag:  ADJ\n",
      "Token:  white POS Tag:  ADJ\n",
      "Token:  rabbit POS Tag:  NOUN\n",
      "Token:  down POS Tag:  ADP\n",
      "Token:  a POS Tag:  DET\n",
      "Token:  \" POS Tag:  PUNCT\n",
      "Token:  Rabbit POS Tag:  NOUN\n",
      "Token:  - POS Tag:  PUNCT\n",
      "Token:  hole POS Tag:  NOUN\n",
      "Token:  \" POS Tag:  PUNCT\n",
      "Token:  . POS Tag:  PUNCT\n"
     ]
    }
   ],
   "source": [
    "for sent in spacy_doc.sents:\n",
    "    for token in sent:\n",
    "        print (\"Token: \", token, \"POS Tag: \", token.pos_)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "08147351cf0926443ffe9cc378ff6e5b19bd752c"
   },
   "source": [
    "### 7. Entity Extraction \n",
    "\n",
    "Using pos tags, Spacy can extract entities as well. Let's see how "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "e83c655e87faf9237ff9a2615facb4b7f6788e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Garden (Label: WORK_OF_ART )\n",
      "Entity: the \"White Rabbit's (Label: LAW )\n",
      "Entity: House (Label: ORG )\n",
      "Entity: The Duchess's Cheshire Cat (Label: WORK_OF_ART )\n",
      "Entity: Alice (Label: PERSON )\n",
      "Entity: the Mad Hatter's (Label: LAW )\n",
      "Entity: Mad Tea-Party (Label: ORG )\n",
      "Entity: Queen (Label: PERSON )\n",
      "Entity: Alice (Label: PERSON )\n",
      "Entity: the White Rabbit (Label: ORG )\n",
      "Entity: Alice (Label: PERSON )\n",
      "Entity: Executioner (Label: WORK_OF_ART )\n"
     ]
    }
   ],
   "source": [
    "for ent in spacy_doc.ents:\n",
    "    if ent.text.strip():\n",
    "        print (\"Entity:\", ent.text, \"(Label:\", ent.label_, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "59dd7fccb08b726db19301621b57da9cf1be87fb"
   },
   "source": [
    "spaCy also provieds a display rendering tool to visualize these entities and their labels. For example : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "1a9f3bbca09caa15768af47cfa688dbfbd12c800"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Alice follows a large white rabbit down a &quot;Rabbit-hole&quot;. She finds a tiny door. When she finds a bottle labeled &quot;Drink me&quot;, she does, and shrinks, but not enough to pass through the door. She then eats something labeled &quot;Eat me&quot; and grows larger. She finds a fan when enables her to shrink enough to get into the &quot;\n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Garden\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       "&quot; and try to get a &quot;Dog&quot; to play with her. She enters \n",
       "<mark class=\"entity\" style=\"background: #ff8197; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the &quot;White Rabbit's\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LAW</span>\n",
       "</mark>\n",
       " tiny \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    House\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ",&quot; but suddenly resumes her normal size. In order to get out, she has to use the &quot;magic fan.&quot;</br>She enters a kitchen, in which there is a cook and a woman holding a baby. She persuades the woman to give her the child and takes the infant outside after the cook starts throwing things around. The baby then turns into a pig and squirms out of her grip. &quot;\n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The Duchess's Cheshire Cat\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       "&quot; appears and disappears a couple of times to \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alice\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and directs her to \n",
       "<mark class=\"entity\" style=\"background: #ff8197; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Mad Hatter's\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LAW</span>\n",
       "</mark>\n",
       " &quot;\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mad Tea-Party\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".&quot; After a while, she leaves.</br>The \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Queen\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " invites \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alice\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " to join the &quot;ROYAL PROCESSION&quot;: a parade of marching playing cards and others headed by \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the White Rabbit\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". When \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alice\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " &quot;unintentionally offends the Queen&quot;, the latter summons the &quot;\n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Executioner\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       "&quot;. Alice &quot;boxes the ears&quot;, then flees when all the playing cards come for her. Then she wakes up and realizes it was all a dream.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(spacy_doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f8e32bbe29e780e714e0c5fe7f922c083e6401e2"
   },
   "source": [
    "### 8. Noun Chunking \n",
    "\n",
    "Similar to entity extraction, one can easily extract noun chunks using spacy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "d64187ae275ccd0070809ba232d169bd759f9033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 1 Alice\n",
      "sentence 1 a large white rabbit\n",
      "sentence 1 a \"Rabbit-hole\n",
      "sentence 2 She\n",
      "sentence 2 a tiny door\n",
      "sentence 3 she\n",
      "sentence 3 a bottle\n",
      "sentence 3 me\n",
      "sentence 3 she\n",
      "sentence 3 shrinks\n",
      "sentence 3 the door\n",
      "sentence 4 She\n",
      "sentence 4 something\n",
      "sentence 4 me\n",
      "sentence 5 She\n",
      "sentence 5 a fan\n",
      "sentence 5 her\n",
      "sentence 5 the \"Garden\n",
      "sentence 5 a \"Dog\n",
      "sentence 5 her\n",
      "sentence 6 She\n",
      "sentence 6 the \"White Rabbit's tiny House\n",
      "sentence 6 her normal size\n",
      "sentence 7 order\n",
      "sentence 7 she\n",
      "sentence 7 the \"magic fan\n",
      "sentence 9 She\n",
      "sentence 9 a kitchen\n",
      "sentence 9 a cook\n",
      "sentence 9 a woman\n",
      "sentence 9 a baby\n",
      "sentence 10 She\n",
      "sentence 10 the woman\n",
      "sentence 10 her\n",
      "sentence 10 the child\n",
      "sentence 10 the infant\n",
      "sentence 10 the cook\n",
      "sentence 10 things\n",
      "sentence 11 The baby\n",
      "sentence 11 a pig\n",
      "sentence 11 her grip\n",
      "sentence 13 The Duchess's Cheshire Cat\n",
      "sentence 13 a couple\n",
      "sentence 13 times\n",
      "sentence 13 Alice\n",
      "sentence 13 her\n",
      "sentence 13 the Mad Hatter's \"Mad Tea-Party\n",
      "sentence 15 a while\n",
      "sentence 15 she\n",
      "sentence 16 The Queen\n",
      "sentence 16 Alice\n",
      "sentence 16 the \"ROYAL PROCESSION\n",
      "sentence 16 a parade\n",
      "sentence 16 playing cards\n",
      "sentence 16 others\n",
      "sentence 16 the White Rabbit\n",
      "sentence 17 Alice\n",
      "sentence 17 the Queen\n",
      "sentence 17 the latter summons\n",
      "sentence 17 the \"Executioner\n",
      "sentence 18 Alice\n",
      "sentence 18 the ears\n",
      "sentence 18 all the playing cards\n",
      "sentence 18 her\n",
      "sentence 19 she\n",
      "sentence 19 it\n",
      "sentence 19 a dream\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(spacy_doc.sents):\n",
    "    for noun in sentence.noun_chunks:\n",
    "        print(f\"sentence {idx+1}\", noun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d2d2e547ada58362e5e1f8c48c1d69cb2270c952"
   },
   "source": [
    "### 9. Dependency Parsing\n",
    "\n",
    "Finally, we look at how can we obtain dependecy grammar relations in the sentences. We will use \"dep\" property for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "835e06d375135c5f01d3f155e601373565bb02e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:  Alice ( nsubj )\n",
      "Token:  follows ( ROOT )\n",
      "Token:  a ( det )\n",
      "Token:  large ( amod )\n",
      "Token:  white ( amod )\n",
      "Token:  rabbit ( dobj )\n",
      "Token:  down ( prep )\n",
      "Token:  a ( det )\n",
      "Token:  \" ( punct )\n",
      "Token:  Rabbit ( compound )\n",
      "Token:  - ( punct )\n",
      "Token:  hole ( pobj )\n",
      "Token:  \" ( punct )\n",
      "Token:  . ( punct )\n"
     ]
    }
   ],
   "source": [
    "for token in list(spacy_doc.sents)[0]:\n",
    "    print (\"Token: \", token.text, \"(\", token.dep_, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e1a5bbf37bc19db79d3707f9abc261a940f22696"
   },
   "source": [
    "Let's visualize the grammar tree as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "9e529e72dbfb041ed8c737d0c8ef22676f60fd70"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"40ef9fc236ed410991c1e031d0013e24-0\" class=\"displacy\" width=\"1550\" height=\"512.0\" direction=\"ltr\" style=\"max-width: none; height: 512.0px; color: white; background: #09a3d5; font-family: Trebuchet MS; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Alice</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">follows</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">large</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">white</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">rabbit</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">down</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">a &quot;</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">Rabbit-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"422.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">hole&quot;.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-40ef9fc236ed410991c1e031d0013e24-0-0\" stroke-width=\"2px\" d=\"M62,377.0 62,352.0 188.0,352.0 188.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-40ef9fc236ed410991c1e031d0013e24-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,379.0 L58,371.0 66,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-40ef9fc236ed410991c1e031d0013e24-0-1\" stroke-width=\"2px\" d=\"M362,377.0 362,302.0 794.0,302.0 794.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-40ef9fc236ed410991c1e031d0013e24-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M362,379.0 L358,371.0 366,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-40ef9fc236ed410991c1e031d0013e24-0-2\" stroke-width=\"2px\" d=\"M512,377.0 512,327.0 791.0,327.0 791.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-40ef9fc236ed410991c1e031d0013e24-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M512,379.0 L508,371.0 516,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-40ef9fc236ed410991c1e031d0013e24-0-3\" stroke-width=\"2px\" d=\"M662,377.0 662,352.0 788.0,352.0 788.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-40ef9fc236ed410991c1e031d0013e24-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M662,379.0 L658,371.0 666,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-40ef9fc236ed410991c1e031d0013e24-0-4\" stroke-width=\"2px\" d=\"M212,377.0 212,277.0 797.0,277.0 797.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-40ef9fc236ed410991c1e031d0013e24-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M797.0,379.0 L801.0,371.0 793.0,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-40ef9fc236ed410991c1e031d0013e24-0-5\" stroke-width=\"2px\" d=\"M212,377.0 212,252.0 950.0,252.0 950.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-40ef9fc236ed410991c1e031d0013e24-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950.0,379.0 L954.0,371.0 946.0,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-40ef9fc236ed410991c1e031d0013e24-0-6\" stroke-width=\"2px\" d=\"M1112,377.0 1112,327.0 1391.0,327.0 1391.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-40ef9fc236ed410991c1e031d0013e24-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1112,379.0 L1108,371.0 1116,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-40ef9fc236ed410991c1e031d0013e24-0-7\" stroke-width=\"2px\" d=\"M1262,377.0 1262,352.0 1388.0,352.0 1388.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-40ef9fc236ed410991c1e031d0013e24-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1262,379.0 L1258,371.0 1266,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-40ef9fc236ed410991c1e031d0013e24-0-8\" stroke-width=\"2px\" d=\"M962,377.0 962,302.0 1394.0,302.0 1394.0,377.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-40ef9fc236ed410991c1e031d0013e24-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1394.0,379.0 L1398.0,371.0 1390.0,371.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options = {'compact': True, 'bg': '#09a3d5', 'color': 'white', 'font': 'Trebuchet MS'}\n",
    "spacy.displacy.render(list(spacy_doc.sents)[0], jupyter=True, style='dep', options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "08bd117a26825dcd76464d6cd7cf90d5f4218878"
   },
   "source": [
    "### 10. Vector Notations \n",
    "\n",
    "Apart from these features spaCy also provides word vector notations of every token which can be used in machine learning tasks. \n",
    "\n",
    "Let's say we have a token = \"King\", we can obtain its vector notations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "5a0b55e199aa992a947408011d5aac859efe6b27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.9139571e+00, -1.0016742e+00, -2.0298631e+00,  4.4045860e-01,\n",
       "       -1.0259339e+00, -1.2732615e+00,  2.3712342e+00,  2.1475315e-02,\n",
       "       -3.2159476e+00,  3.0835030e+00,  8.9685857e-01, -1.1318004e+00,\n",
       "       -2.7188659e-04,  9.1702992e-01,  1.1167799e+00, -2.8955281e-01,\n",
       "       -5.2588457e-01,  1.3412244e+00, -2.5638943e+00,  3.1032321e+00,\n",
       "       -7.6287359e-02, -7.2169220e-01,  1.8055359e+00, -5.2969289e-01,\n",
       "       -9.8598915e-01, -9.1488719e-01,  4.5880005e-01, -1.2740700e+00,\n",
       "        1.5132586e+00, -1.8060904e+00, -1.7065288e+00, -1.3216652e+00,\n",
       "        4.8007736e+00, -1.3426158e-01, -9.9779117e-01,  4.3230295e+00,\n",
       "        3.6356062e-01, -1.6250321e+00, -1.2807019e+00, -1.2762814e+00,\n",
       "        1.4773902e+00,  5.6884813e+00,  1.1288882e+00, -8.6327398e-01,\n",
       "        7.0138943e-01, -3.8181849e+00,  3.5870168e-01,  4.8530350e+00,\n",
       "       -1.0350798e+00, -3.5739625e-01, -4.5156498e+00, -8.2374805e-01,\n",
       "        2.0293598e+00, -3.8062379e-01, -1.6465067e+00,  1.8852234e+00,\n",
       "        1.9861157e+00, -8.1921154e-01, -1.4533647e+00,  3.9240664e-01,\n",
       "       -9.4181937e-01, -5.5911326e-01, -4.8667282e-02, -2.9735751e+00,\n",
       "        3.5969958e+00,  3.5400681e+00,  2.8004804e+00, -1.0811818e+00,\n",
       "        7.0557648e-01, -7.0945472e-02,  4.1793075e-01,  1.2463605e+00,\n",
       "        9.7768050e-01, -2.8816731e+00,  4.8173666e-03, -5.9768343e-01,\n",
       "        1.0247577e+00,  7.1092260e-01,  1.1206573e+00,  7.5635195e-01,\n",
       "        1.6326574e+00, -2.0251951e+00, -1.4660387e+00, -1.1351033e+00,\n",
       "       -3.9435685e-01, -4.4243193e-01,  8.1707823e-01, -1.2179613e-02,\n",
       "       -1.7369132e+00, -2.2315640e+00, -3.0358791e+00,  2.7751215e+00,\n",
       "       -8.9954990e-01, -5.7506871e-01,  2.2371750e+00, -4.0365715e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = nlp(u'king')\n",
    "token.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "703bc546bae77b987175f3178947a9b083116c46"
   },
   "source": [
    "Let's also print the vector of the token = \"man\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "976089889ff60602b5c78ee74e83f9e0509b3a9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7088207 , -0.37977344, -0.39255697,  1.5627415 , -2.867544  ,\n",
       "        1.7395227 ,  1.2475766 ,  0.30651206,  1.6436899 ,  3.5380862 ,\n",
       "        0.19831753, -1.7071538 ,  0.5145009 ,  0.69034517, -0.14347413,\n",
       "        1.3977473 ,  1.4867508 ,  0.06117857, -2.7757516 ,  1.8932886 ,\n",
       "        1.6243601 , -0.16163284, -0.17025247, -1.3997722 , -0.15662324,\n",
       "       -0.79690444, -0.9151953 , -1.0312278 ,  3.9805896 , -1.37117   ,\n",
       "       -0.91109014, -0.10652265,  1.6504273 , -1.8971703 ,  1.5930436 ,\n",
       "        1.9742754 ,  0.21027347, -0.28525767, -1.2498834 , -0.3620946 ,\n",
       "        3.277402  ,  3.273175  , -0.64561605, -0.86335456,  2.0143979 ,\n",
       "       -2.1200714 ,  1.1332449 ,  1.0214756 , -2.935066  , -1.0889438 ,\n",
       "       -2.7789528 , -0.67337126,  3.032012  , -1.5588952 , -1.6748934 ,\n",
       "        0.5104773 ,  0.7180389 , -0.9961107 , -1.346349  , -0.5172305 ,\n",
       "       -0.25415683, -1.8575006 ,  2.0072165 ,  0.17103535,  1.9901856 ,\n",
       "        1.7427328 ,  1.8114712 , -0.72808653, -0.6118781 , -0.80624664,\n",
       "        0.5574479 ,  1.5578572 ,  2.3864174 , -0.84202737,  0.9777938 ,\n",
       "        1.2409612 ,  0.79395926,  0.2801109 ,  1.6222427 ,  0.37677923,\n",
       "        0.5451237 , -2.572692  ,  0.02171731,  0.3428989 , -1.7743161 ,\n",
       "       -2.592222  ,  0.6519879 ,  0.14626202, -1.6256323 , -2.630528  ,\n",
       "       -3.1053658 ,  2.3336267 , -1.0442933 , -0.9279148 , -1.905375  ,\n",
       "       -1.8137105 ], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2 = nlp(u'man')\n",
    "token2.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token2.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9905bf99e7d480f6800465d645f831ddcc2763ab"
   },
   "source": [
    "We can use these notations and find document similarity. For example : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "7589a07b84b60e4491c6309fb43f8c5277d76010"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-72cda8168cd6>:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  token.similarity(token2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6450098646874819"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.similarity(token2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b498c641518b3e9c10d333afc45c0da2ce3f7748"
   },
   "source": [
    "The result states that the similarity score of the two documents is 0.76 / 1. \n",
    "\n",
    "## End Notes \n",
    "\n",
    "This notebook explains the basics of NLP techniques applied using spaCy. These techniques can be used to generate text based features, generate vector notations,  document similarity, improve topic models, imporve machine and deep learning models, and build knowledge graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
